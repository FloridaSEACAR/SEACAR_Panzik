---
date: "Last compiled on `r format(Sys.time(), '%d %B, %Y')`"
output:
  word_document:
    toc: TRUE
    toc_depth: 2
  html_document:
    toc: TRUE
    toc_float: TRUE
    toc_depth: 2
    dev: png
    keep_md: yes
  pdf_document:
    toc: TRUE
    toc_depth: 2
    dev: png
    extra_dependencies: ["float"]
    keep_md: yes
urlcolor: blue
params:
  managedarea: "Alligator Harbor Aquatic Preserve"
---

# Important Notes

The purpose of this script is to create managed area statistics, perform seasonal Kendall Tau analysis, generate summary plots, and create reports in pdf and Word document form for each parameter in Wc Discrete.

These scripts were created by [J.E. Panzik](mailto:jepanzik@usf.edu) (jepanzik@usf.edu) for SEACAR.
The scripts were modified by [T.G. Hill](mailto:Tyler.Hill@FloridaDEP.gov) (Tyler.Hill@FloridaDEP.gov) in August of 2023, to create individual reports for each Managed Area.

All scripts and outputs can be found on the SEACAR GitHub repository:

https://github.com/FloridaSEACAR/SEACAR_Trend_Analyses

This markdown file is designed to be compiled by [WC_Discrete_ReportRender.R](https://github.com/FloridaSEACAR/SEACAR_Trend_Analyses/blob/main/WC_Discrete/WC_Discrete_ReportRender.R) (https://github.com/FloridaSEACAR/SEACAR_Trend_Analyses/blob/main/WC_Discrete/WC_Discrete_ReportRender.R).

Note: The top 2% of data is excluded when computing mean and standard deviations in plotting sections solely for the purpose of getting y-axis scales. The exclusion of the top 2% is not used in any statistics that are exported.



```{r libraries, message=FALSE, echo = FALSE}
library(knitr)
library(data.table)
library(dplyr)
library(lubridate)
library(ggplot2)
library(ggpubr)
library(scales)
library(EnvStats)
library(tidyr)
library(kableExtra)
options(scipen=999)
knitr::opts_chunk$set(
   warning=FALSE,
   message=FALSE,
   echo=FALSE,
   dpi=200
)
```

# File Import

Imports file that is determined in the WC_Discrete_ReportRender.R script. 

The command `fread` is used because of its improved speed while handling large data files. Only columns that are used by the script are imported from the file, and are designated in the `select` input.

The script then gets the name of the parameter as it appears in the data file and units of the parameter.

The latest version of WC Discrete data is available at: https://usf.box.com/s/fbimxw4hrmazfn5b1d4jbn0addmcsld8

The file being used for the analysis is: **`r file_short`**

```{r file_import}
data <- fread(file_in, sep="|", header=TRUE, stringsAsFactors=FALSE,
        select=c("ManagedAreaName", "ProgramID", "ProgramName",
              "ProgramLocationID", "SampleDate", "Year", "Month",
              "RelativeDepth", "ActivityType", "ParameterName",
              "ResultValue", "ParameterUnits", "ValueQualifier",
              "SEACAR_QAQCFlagCode", "Include"),
        na.strings=c("NULL","","NA"))

parameter <- unique(data$ParameterName)
unit <- unique(data$ParameterUnits)
cat(paste("The data file(s) used:", file_short, sep="\n"))
```

---
title: '`r paste("SEACAR Discrete Water Quality Analysis:", activity, depth, unique(data$ParameterName), params$managedarea)`'
---

```{r filtering}
# Removes data rows with missing ResultValue
data <- data[!is.na(data$ResultValue),]
# Changes "Sample" to "Lab" for ActivityType
data$ActivityType <- gsub("Sample", "Lab", data$ActivityType)

# Gets data for the specific activity type if it is not All
if(activity!="All"){
   data <- data[grep(activity, data$ActivityType),]
}

# Changes RelativeDepth to Bottom for the QAQC flag 12Q that indicates
# measurements are both surface and bottom if the relative depth is bottom
if(depth=="Bottom"){
   data$RelativeDepth[grep("12Q", data$SEACAR_QAQCFlagCode[
      data$RelativeDepth=="Surface"])] <- "Bottom"
}
# Removes missing RelativeDepth data and data for RelativeDepth not of interest
# from all parameters except Secchi_Depth
if(param_name!="Secchi_Depth" & depth!="All"){
   data <- data[!is.na(data$RelativeDepth),]
   data <- data[data$RelativeDepth==depth,]
}

# Removes data rows that have "Blank" as an ActivityType
if(length(grep("Blank", data$ActivityType))>0){
   data <- data[-grep("Blank", data$ActivityType),]
}

# Removes data rows with ResultValue below 0, or -2 for Water_Temperature
if(param_name=="Water_Temperature"){
   data <- data[data$ResultValue>=-2,]
} else{
   data <- data[data$ResultValue>=0,]
}
# Changes Include to be either TRUE or FALSE
data$Include <- as.logical(data$Include)
# Changes Include to be TRUE for ProgramID 476 if it had the H value qualifier
data$Include[grep("H", data$ValueQualifier[data$ProgramID==476])] <- TRUE
# Change Include to be FALSE for Secchi_Depth with U value qualifier
if(param_name=="Secchi_Depth"){
   data$Include[grep("U", data$ValueQualifier)] <- FALSE
}
# Gets AreaID for data by merging data with the managed area list
data <- merge.data.frame(MA_All[,c("AreaID", "ManagedAreaName")],
             data, by="ManagedAreaName", all=TRUE)
# Creates function to checks managed area for at least 2 years of
# continuous consecutive data
DiscreteConsecutiveCheck <- function(con_data){
   # Gets AreaIDs
   IDs <- unique(con_data$AreaID[con_data$Include==TRUE &
                     !is.na(con_data$Include)])
   # Loops through each AreaID
   for(i in 1:length(IDs)) {
      # Gets list of Years for AreaID
      Years <- unique(con_data$Year[con_data$AreaID==IDs[i] &
                        con_data$Include==TRUE &
                        !is.na(con_data$Include)])
      # Puts Years in order
      Years <- Years[order(Years)]
      # If there are fewer than 2 years, skip to next AreaID
      if(length(Years)<2) {
         next
      }
      # Starts loop to make sure there are at least 2 consecutive years
      # with consecutive months of data
      for(j in 2:length(Years)) {
         # If adjacent year entries are not 1 year apart, skip to the
         # next set of year entries
         if(Years[j]-Years[j-1]!=1) {
            next
         }
         # Gets the list of months from the first year
         Months1 <- unique(con_data$Month[
            con_data$AreaID==IDs[i] &
               con_data$Year==Years[j-1] &
               con_data$Include==TRUE &
               !is.na(con_data$Include)])
         # Gets list of months for the second year
         Months2 <- unique(con_data$Month[
            con_data$AreaID==IDs[i] &
               con_data$Year==Years[j] &
               con_data$Include==TRUE &
               !is.na(con_data$Include)])
         # If there are more than 2 months shared between the two
         # years, the AreaID passes the check and is stored
         if(length(intersect(Months1, Months2))>=2) {
            # Creates variable for stored AreaID if it
            # doesn't exist
            if(exists("consecutive")==FALSE){
               consecutive <- IDs[i]
               break
            # Adds to variable for storing AreaID if does exist
            } else{
               consecutive <- append(consecutive, IDs[i])
               break
            }
         }
      }
   }
   # After going through all AreaID, return variable with list of all
   # that pass
   return(consecutive)
}
# Stores the AreaID that pass the consecutive year check
consMonthIDs <- DiscreteConsecutiveCheck(data)

# Creates data frame with summary for each managed area
MA_Summ <- data %>%
   group_by(AreaID, ManagedAreaName) %>%
   summarize(ParameterName=parameter,
          RelativeDepth=depth,
          ActivityType=activity,
          N_Data=length(ResultValue[Include==TRUE & !is.na(ResultValue)]),
          N_Years=length(unique(Year[Include==TRUE & !is.na(Year)])),
          EarliestYear=min(Year[Include==TRUE & N_Data!=0]),
          LatestYear=max(Year[Include==TRUE & N_Data!=0]),
          EarliestSampleDate=min(SampleDate[Include==TRUE]),
          LastSampleDate=max(SampleDate[Include==TRUE]),
          ConsecutiveMonths=ifelse(unique(AreaID) %in%
                          consMonthIDs==TRUE, TRUE, FALSE),
          # Determines if monitoring location is sufficient for analysis
          # based on having more than 0 data entries, more than the
          # sufficient number of year, and the consecutive month criteria
          SufficientData=ifelse(N_Data>0 & N_Years>=suff_years &
                       ConsecutiveMonths==TRUE, TRUE, FALSE),
          Median=median(ResultValue[Include==TRUE & N_Data!=0], na.rm=TRUE))

MA_Summ$ConsecutiveMonths <- NULL
# Creates column in data that determines how many years from the start for each
# managed area
data <- data %>%
   group_by(AreaID, ManagedAreaName) %>%
   mutate(YearFromStart=Year-min(Year))
# Adds SufficientData column to data table based on managed area
data <- merge.data.frame(data, MA_Summ[,c("ManagedAreaName", "SufficientData")],
             by="ManagedAreaName")
# Creates Use_In_Analysis column for data that is determined if the row has
# Include value of TRUE and SufficientData value of TRUE
data$Use_In_Analysis <- ifelse(data$Include==TRUE & data$SufficientData==TRUE,
                TRUE, FALSE)
# Rearranges the summary data frame columns to be AreaID, ManagedAreaName,
# ParameterName RelativeDepth, ActivityType, SufficientData, everything else
MA_Summ <- MA_Summ %>%
   select(AreaID, ManagedAreaName, ParameterName, RelativeDepth, ActivityType,
       SufficientData, everything())
# Puts summary data in order based on managed area
MA_Summ <- as.data.frame(MA_Summ[order(MA_Summ$ManagedAreaName), ])
# Put SampleDate as date object
data$SampleDate <- as.Date(data$SampleDate)
# Creates character object for Month and Year
data$YearMonth <- paste0(data$Month, "-", data$Year)
# Creates variable that puts year and month into a decimal year format
data$YearMonthDec <- data$Year + ((data$Month-0.5) / 12)
# Converts ampleDate to a decimal date
data$DecDate <- decimal_date(data$SampleDate)

# Get list of and number of managed areas that are to be used in analysis
MA_Include <- MA_Summ$ManagedAreaName[MA_Summ$SufficientData==TRUE]
n <- length(MA_Include)
# Get list of and number of managed areas that are excluded from analysis
MA_Exclude <- MA_Summ[MA_Summ$N_Years<10 & MA_Summ$N_Years>0,]
MA_Exclude <- MA_Exclude[,c("ManagedAreaName", "N_Years")]
z <- nrow(MA_Exclude)
```



# Data Impacted by Specific Value Qualifiers

Reports the amount of data impacted by the H (for dissolved oxygen & pH in program 476), I, Q, S (for Secchi depth), and U value qualifiers. It determines how much of the data for the given `ParametetrName`, `RelativeDepth`, and `ActivityType` is impacted by each value qualifier. Percentages are determined using 100*(# of value qualifier)/(# of total data)

A variable is also created that determines if scatter plot points should be a different color based on value qualifiers of interest.

A summary data frame is created that determines the amount of data and percentage of data impacted by the value qualifiers for each managed area by year and is written to a csv file in the output directory. Columns with `N` are the number impacted by the value qualifier, and those with `perc` are the percent of the data for that managed area and year impacted by the value qualifier.
   + [WC Discrete Output Files in SEACAR GitHub](https://github.com/FloridaSEACAR/SEACAR_Trend_Analyses/tree/main/WQ_Discrete/output) (https://github.com/FloridaSEACAR/SEACAR_Trend_Analyses/tree/main/WQ_Discrete/output)


```{r}
# Find out how much total data exists and how much passed the initial filters
total <- length(data$Include)
pass_filter <- length(data$Include[data$Include==TRUE])
# Get the number and percentage of data entries impacted by value qualifier H
count_H <- length(grep("H", data$ValueQualifier[data$ProgramID==476]))
perc_H <- 100*count_H/length(data$ValueQualifier)
# Get the number and percentage of data entries impacted by value qualifier I
count_I <- length(grep("I", data$ValueQualifier))
perc_I <- 100*count_I/length(data$ValueQualifier)
# Get the number and percentage of data entries impacted by value qualifier Q
count_Q <- length(grep("Q", data$ValueQualifier))
perc_Q <- 100*count_Q/length(data$ValueQualifier)
# Get the number and percentage of data entries impacted by value qualifier S
count_S <- length(grep("S", data$ValueQualifier))
perc_S <- 100*count_S/length(data$ValueQualifier)
# Get the number and percentage of data entries impacted by value qualifier U
count_U <- length(grep("U", data$ValueQualifier))
perc_U <- 100*count_U/length(data$ValueQualifier)
# Copy ValueQualifier to a new VQ_Plot to create codes for plots
data$VQ_Plot <- data$ValueQualifier
# Determine if data with value qualifier H should be included for plots based
# on the parameter being observed
inc_H <- ifelse(param_name=="pH" | param_name=="Dissolved_Oxygen" |
          param_name=="Dissolved_Oxygen_Saturation", TRUE, FALSE)
# Loops through conditions to determine what indicators to include in plots.
# If H should be included
if (inc_H==TRUE){
      # Remove any Value qualifiers that aren't H or U
      data$VQ_Plot <- gsub("[^HU]+", "", data$VQ_Plot)
      # Standardize order of qualifiers. Puts UH as HU
      data$VQ_Plot <- gsub("UH", "HU", data$VQ_Plot)
      # Remove anything from ValueQualifier that isn't U from programs and that
      # aren't ProgramID 476
      data$VQ_Plot[na.omit(data$ProgramID!=476)] <-
            gsub("[^U]+", "", data$VQ_Plot[na.omit(data$ProgramID!=476)])
      # Changes blank character strings to NA
      data$VQ_Plot[data$VQ_Plot==""] <- NA
      # Prints the number and percentage of H, I, Q, U value qualifiers
      cat(paste0("Number of Measurements: ", total,
                 ", Number Passed Filter: ", pass_filter, "\n",
                 "Program 476 H Codes: ", count_H, " (", round(perc_H, 6), "%)\n",
                 "I Codes: ", count_I, " (", round(perc_I, 6), "%)\n",
                 "Q Codes: ", count_Q, " (", round(perc_Q, 6), "%)\n",
                 "U Codes: ", count_U, " (", round(perc_U, 6), "%)"))
# If Parameter is Secchi_Depth
} else if (param_name=="Secchi_Depth") {
      # Count the number of S ValueQualifier
      count_S <- length(grep("S", data$ValueQualifier))
      # Get percentage of S ValueQualifier
      perc_S <- 100*count_S/length(data$ValueQualifier)
      # Remove anything from ValueQualifier that isn't S or U
      data$VQ_Plot <- gsub("[^SU]+", "", data$VQ_Plot)
      # Change all ValueQualifier that are US to be US, standardizes codes
      data$VQ_Plot <- gsub("US", "SU", data$VQ_Plot)
      # Sets any blank character ValueQualifier to be NA
      data$VQ_Plot[data$VQ_Plot==""] <- NA
      # Prints the number and percentage of I, Q, S, U
      cat(paste0("Number of Measurements: ", total,
                 ", Number Passed Filter: ", pass_filter, "\n",
                 "I Codes: ", count_I, " (", round(perc_I, 6), "%)\n",
                 "Q Codes: ", count_Q, " (", round(perc_Q, 6), "%)\n",
                 "S Codes: ", count_S, " (", round(perc_S, 6), "%)\n",
                 "U Codes: ", count_U, " (", round(perc_U, 6), "%)"))
# For all other scenarios
} else{
      # Remove all ValueQualifier except U
      data$VQ_Plot <- gsub("[^U]+", "", data$VQ_Plot)
      # Sets any blank character ValueQualifier to be NA
      data$VQ_Plot[data$VQ_Plot==""] <- NA
      # Prints the number and percentage of I, Q, U
      cat(paste0("Number of Measurements: ", total,
                 ", Number Passed Filter: ", pass_filter, "\n",
                 "I Codes: ", count_I, " (", round(perc_I, 6), "%)\n",
                 "Q Codes: ", count_Q, " (", round(perc_Q, 6), "%)\n",
                 "U Codes: ", count_U, " (", round(perc_U, 6), "%)"))
}
# Creates a data table that summarizes the number and percentage of
# ValueQualifier H, I, Q, S, and U for each managed area each year
data_summ <- data %>%
      group_by(AreaID, ManagedAreaName, Year) %>%
      summarize(ParameterName=parameter,
                RelativeDepth=depth,
                ActivityType=activity,
                N_Total=length(ResultValue),
                N_AnalysisUse=length(ResultValue[Use_In_Analysis==TRUE]),
                N_H=length(grep("H", ValueQualifier[ProgramID==476])),
                perc_H=100*N_H/length(ValueQualifier),
                N_I=length(grep("I", ValueQualifier)),
                perc_I=100*N_I/length(ValueQualifier),
                N_Q=length(grep("Q", ValueQualifier)),
                perc_Q=100*N_Q/length(ValueQualifier),
                N_S=length(grep("S", ValueQualifier)),
                perc_S=100*N_S/length(ValueQualifier),
                N_U=length(grep("U", ValueQualifier)),
                perc_U=100*N_U/length(ValueQualifier))
# Orders the data table rows based on managed area name
data_summ <- as.data.table(data_summ[order(data_summ$ManagedAreaName,
                                           data_summ$Year), ])
# Writes the ValueQualifier summary to a csv file
fwrite(data_summ, paste0(out_dir_param,"/WC_Discrete_", param_abrev, "_",
                         activity, "_", depth, "_VQSummary.csv"), sep=",")
rm(data_summ)
```

<!-- Managed Area Statistics (not shown) -->

```{r managed_area_stats, message=FALSE}
# Create summary statistics for each managed area based on Year and Month
# intervals.
MA_YM_Stats <- data[data$Use_In_Analysis==TRUE, ] %>%
   group_by(AreaID, ManagedAreaName, Year, Month) %>%
   summarize(ParameterName=parameter,
       RelativeDepth=depth,
       ActivityType=activity,
       N_Data=length(ResultValue),
       Min=min(ResultValue),
       Max=max(ResultValue),
       Median=median(ResultValue),
       Mean=mean(ResultValue),
       StandardDeviation=sd(ResultValue),
       Programs=paste(sort(unique(ProgramName), decreasing=FALSE),
               collapse=', '),
       ProgramIDs=paste(sort(unique(ProgramID), decreasing=FALSE),
               collapse=', '))
# Puts the data in order based on ManagedAreaName, Year, then Month
MA_YM_Stats <- as.data.table(MA_YM_Stats[order(MA_YM_Stats$ManagedAreaName,
                          MA_YM_Stats$Year,
                          MA_YM_Stats$Month), ])
# Writes summary statistics to file
fwrite(MA_YM_Stats, paste0(out_dir_param,"/WC_Discrete_", param_abrev, "_",
               activity, "_", depth, "_MA_MMYY_Stats.txt"), sep="|")
# Get year from start for each managed area to be used in SKT analysis
MA_YM_Stats <- MA_YM_Stats %>%
   group_by(AreaID, ManagedAreaName) %>%
   mutate(YearFromStart=Year-min(Year))
# Create decimal value of year and month values
MA_YM_Stats$YearMonthDec <- MA_YM_Stats$Year + ((MA_YM_Stats$Month-0.5) / 12)
# Create summary statistics for each managed area based on Year intervals.
MA_Y_Stats <- data[data$Use_In_Analysis==TRUE, ] %>%
   group_by(AreaID, ManagedAreaName, Year) %>%
   summarize(ParameterName=parameter,
       RelativeDepth=depth,
       ActivityType=activity,
       N_Data=length(ResultValue),
       Min=min(ResultValue),
       Max=max(ResultValue),
       Median=median(ResultValue),
       Mean=mean(ResultValue),
       StandardDeviation=sd(ResultValue),
       Programs=paste(sort(unique(ProgramName), decreasing=FALSE),
               collapse=', '),
       ProgramIDs=paste(sort(unique(ProgramID), decreasing=FALSE),
               collapse=', '))
# Puts the data in order based on ManagedAreaName then Year
MA_Y_Stats <- as.data.table(MA_Y_Stats[order(MA_Y_Stats$ManagedAreaName,
                        MA_Y_Stats$Year), ])
# Writes summary statistics to file
fwrite(MA_Y_Stats, paste0(out_dir_param,"/WC_Discrete_", param_abrev, "_",
               activity, "_", depth, "_MA_Yr_Stats.txt"), sep="|")
rm(MA_Y_Stats)
# Create summary statistics for each managed area based on Month intervals.
MA_M_Stats <- data[data$Use_In_Analysis==TRUE, ] %>%
   group_by(AreaID, ManagedAreaName, Month) %>%
   summarize(ParameterName=parameter,
       RelativeDepth=depth,
       ActivityType=activity,
       N_Data=length(ResultValue),
       Min=min(ResultValue),
       Max=max(ResultValue),
       Median=median(ResultValue),
       Mean=mean(ResultValue),
       StandardDeviation=sd(ResultValue),
       Programs=paste(sort(unique(ProgramName), decreasing=FALSE),
               collapse=', '),
       ProgramIDs=paste(sort(unique(ProgramID), decreasing=FALSE),
               collapse=', '))
# Puts the data in order based on ManagedAreaName then Month
MA_M_Stats <- as.data.table(MA_M_Stats[order(MA_M_Stats$ManagedAreaName,
                        MA_M_Stats$Month), ])
# Writes summary statistics to file
fwrite(MA_M_Stats, paste0(out_dir_param,"/WC_Discrete_", param_abrev, "_",
               activity, "_", depth, "_MA_Mo_Stats.txt"), sep="|")
rm(MA_M_Stats)
```

<!-- Monitoring Location Statistics -->

```{r monitoring_loc_stats, message=FALSE}
# Gets summary statistics for monitoring locations, which are defined as unique
# combinations of ManagedAreaName, ProgramID, And ProgramLocationID
Mon_Stats <- data[data$Use_In_Analysis==TRUE, ] %>%
   group_by(AreaID, ManagedAreaName, ProgramID, ProgramName,
            ProgramLocationID) %>%
   summarize(ParameterName=parameter,
       RelativeDepth=depth,
       ActivityType=activity,
       EarliestSampleDate=min(SampleDate),
       LastSampleDate=max(SampleDate),
       N_Data=length(ResultValue),
       Min=min(ResultValue),
       Max=max(ResultValue),
       Median=median(ResultValue),
       Mean=mean(ResultValue),
       StandardDeviation=sd(ResultValue))
# Order data rows by ManagedAreaName, ProgramName, ProgramID, then
# ProgramLocationID
Mon_Stats <- as.data.table(Mon_Stats[order(Mon_Stats$ManagedAreaName,
                      Mon_Stats$ProgramName,
                      Mon_Stats$ProgramID, 
                      Mon_Stats$ProgramLocationID), ])
# Write summary statistics to file
fwrite(Mon_Stats, paste0(out_dir_param,"/WC_Discrete_", param_abrev, "_",
               activity, "_", depth, "_MonLoc_Stats.txt"), sep="|")
rm(Mon_Stats)
```


# Seasonal Kendall Tau Analysis

Gets seasonal Kendall Tau statistics using the `kendallSeasonalTrendTest` from the `EnvStats` package. The `Trend` parameter is determined from a user-defined function based on the median, Senn slope, and p values from the data. Analysis modified from code created by Jason Scolaro that performed at The Water Atlas:
[https://sarasota.wateratlas.usf.edu/water-quality-trends/#analysis-overview](https://sarasota.wateratlas.usf.edu/water-quality-trends/#analysis-overview)

The following steps are performed:

1. Set the column names for the variable holding the SKT stat values
2. Create a data frame with the same number of columns as column names, and the same number of rows as the number of managed areas being analyzed.
3. Starts a loop that goes through each managed area
4. Gets data for that ManagedAreaName and the number of data rows.
5. Gets basic statistics for the ManagedAreaName from the MA_Summ variable.
6. Performs a seasonal Kendall Tau trend test with the assumption that data is not serially correlated (independent.obs=TRUE)
   + If analysis returns NULL, performs SKT assuming data is serially auto-correlated (independent.obs=FALSE)

7. Store the SKT result values in the skt_stats data frame created.
8. Determines the Trend of the slope based on the statistics and SKT parameters.
9. Merge data frames together to create a cumulative data frame with all statistics and round values to appropriate decimal points.
10. Write summary stats to a pipe-delimited .txt file in the output directory
   + [WC Discrete Output Files in SEACAR GitHub](https://github.com/FloridaSEACAR/SEACAR_Trend_Analyses/tree/main/WQ_Discrete/output) (https://github.com/FloridaSEACAR/SEACAR_Trend_Analyses/tree/main/WQ_Discrete/output)
   
```{r SKT_analysis}
# List for column names
c_names <- c("AreaID", "ManagedAreaName", "Independent", "tau", "p",
             "SennSlope", "SennIntercept", "ChiSquared", "pChiSquared", "Trend")

skt_stats <- data.frame(matrix(ncol = length(c_names), nrow = n))

colnames(skt_stats) <- c_names
# Determines if there are any managed areas to analyze
if(n==0){
   print("There are no managed areas that qualify.")
} else{
   # Starts cycling through managed areas to determine seasonal Kendall Tau
   for (i in 1:n) {
      # Gets the number of rows of data for the managed area
      data_SKT <- MA_YM_Stats[MA_YM_Stats$ManagedAreaName==MA_Include[i], ]
      x <- nrow(data_SKT)
      # Perform analysis if there is more than 1 row
      if (x>0) {
         # Store the managed area summary statistics to be used in
         # trend analysis
         SKT.med <- MA_Summ$Median[MA_Summ$ManagedAreaName==MA_Include[i]]
         SKT.minYr <- MA_Summ$EarliestYear[MA_Summ$ManagedAreaName==
                                              MA_Include[i]]
         SKT.maxYr <- MA_Summ$LatestYear[MA_Summ$ManagedAreaName==MA_Include[i]]
         SKT.ind <- TRUE
         SKT <- kendallSeasonalTrendTest(y=data_SKT$Mean,
                                         season=data_SKT$Month,
                                         year=data_SKT$YearFromStart,
                                         independent.obs=SKT.ind)
         if(is.na(SKT$estimate[1])==TRUE){
            SKT.ind <- FALSE
            SKT <- kendallSeasonalTrendTest(y=data_SKT$Mean,
                                            season=data_SKT$Month,
                                            year=data_SKT$YearFromStart,
                                            independent.obs=SKT.ind)
         }
         skt_stats$AreaID[i] <-
            MA_Summ$AreaID[MA_Summ$ManagedAreaName==MA_Include[i]]
         skt_stats$ManagedAreaName[i] <-
            MA_Summ$ManagedAreaName[MA_Summ$ManagedAreaName==MA_Include[i]]
         skt_stats$Independent[i] <- SKT.ind
         skt_stats$tau[i] <- SKT$estimate[1]
         skt_stats$p[i] <- SKT$p.value[2]
         skt_stats$SennSlope[i] <- SKT$estimate[2]
         skt_stats$SennIntercept[i] <- SKT$estimate[3]
         skt_stats$ChiSquared[i] <- SKT$statistic[1]
         skt_stats$pChiSquared[i] <- SKT$p.value[1]
         # If the p value is less than 5% and the slope is greater than 10% of the
         # median value, the trend is large (2).
         if (skt_stats$p[i] < .05 & abs(skt_stats$SennSlope[i]) >
             abs(SKT.med) / 10.) {
            skt_stats$Trend[i] <- 2
            
            # If the p value is less than 5% and the slope is less than 10% of the
            # median value, there is a trend (1).
         }else if (skt_stats$p[i] < .05 & abs(skt_stats$SennSlope[i]) <
                   abs(SKT.med) / 10.) {
            skt_stats$Trend[i] <- 1
            
            # Otherwise, there is no trend (0)
         }else {
            skt_stats$Trend[i] <- 0
         }
         # Sets the sign of the trend based on Senn Slope direction
         if (skt_stats$SennSlope[i] <= 0) {
            skt_stats$Trend[i] <- -skt_stats$Trend[i]
         }
      }
   }
   
   # Stores as data frame
   skt_stats <- as.data.frame(skt_stats)
  
}
# Clears unused variables
rm(SKT, data_SKT, x, SKT.med, SKT.minYr, SKT.maxYr, SKT.ind)
# Combines the skt_stats with MA_Summ
skt_stats <-  merge.data.frame(MA_Summ, skt_stats,
                              by=c("AreaID","ManagedAreaName"), all=TRUE)

skt_stats <- as.data.table(skt_stats[order(skt_stats$ManagedAreaName), ])

# Sets variables to proper format and rounds values if necessary
skt_stats$tau <- round(as.numeric(skt_stats$tau), digits=4)
skt_stats$p <- format(round(as.numeric(skt_stats$p), digits=4),
                     scientific=FALSE)
skt_stats$SennSlope <- as.numeric(skt_stats$SennSlope)
skt_stats$SennIntercept <- as.numeric(skt_stats$SennIntercept)
skt_stats$ChiSquared <- round(as.numeric(skt_stats$ChiSquared), digits=4)
skt_stats$pChiSquared <- round(as.numeric(skt_stats$pChiSquared), digits=4)
skt_stats$Trend <- as.integer(skt_stats$Trend)

# Writes combined statistics to file
fwrite(select(skt_stats, -c(EarliestSampleDate)),
       paste0(out_dir_param,"/WC_Discrete_", param_abrev, "_",
              activity, "_", depth, "_KendallTau_Stats.txt"),
       sep="|")

# Removes data rows with no ResultValue (created by merging with MA_All)
data <- data[!is.na(data$ResultValue),]

# Gets x and y values for starting point for trendline
KT.Plot <- skt_stats %>%
   group_by(ManagedAreaName) %>%
   summarize(x=decimal_date(EarliestSampleDate),
             y=(x-EarliestYear)*SennSlope+SennIntercept)
# Gets x and y values for ending point for trendline
KT.Plot2 <- skt_stats %>%
   group_by(ManagedAreaName) %>%
   summarize(x=decimal_date(LastSampleDate),
             y=(x-EarliestYear)*SennSlope+SennIntercept)
# Combines the starting and endpoints for plotting the trendline
KT.Plot <- bind_rows(KT.Plot, KT.Plot2)
rm(KT.Plot2)
KT.Plot <- as.data.table(KT.Plot[order(KT.Plot$ManagedAreaName), ])
KT.Plot <- KT.Plot[!is.na(KT.Plot$y),]

```

# Appendix I: Managed Area Trendlines

The plots created in this section are designed to show the general trend of the data. Data is taken and grouped by `ManagedAreaName`. The trendlines on the plots are created using the Senn slope and intercept from the seasonal Kendall Tau analysis. The scripts that create plots follow this format:

1. Use the data set that only has `SufficientData` of `TRUE` for the desired managed area
2. Determine the earliest and latest year of the data to create x-axis scale and intervals
3. Determine the minimum, mean, and standard deviation for the data to be used for y-axis scales
   + Excludes the top 2% of values to reduce the impact of extreme outliers on the y-axis scale

4. Set what values are to be used for the x-axis, y-axis, and the variable that should determine groups for the plots
5. Set the plot type as a point plot with the size of the points
6. Add the linear trend
7. Create the title, x-axis, y-axis, and color fill labels
8. Set the y and x limits
9. Make the axis labels bold
10. Plot the arrangement as a set of panels


```{r Trendlines_ManagedArea, warning=FALSE, fig.height=9, fig.width=10, results="asis", eval=APP_Plots}
# Setting y-labels for all plots
y_labels <- paste0(parameter, " (" , unit, ")")
# Gets data to be used in plot for managed area
plot_data <- MA_YM_Stats[MA_YM_Stats$ManagedAreaName==params$managedarea,]
# Gets trendline data for managed area
KT.plot_data <- KT.Plot[KT.Plot$ManagedAreaName==params$managedarea,]
#Determine max and min time (Year) for plot x-axis
t_min <- min(plot_data$Year)
t_max <- max(plot_data$YearMonthDec)
t_max_brk <- as.integer(round(t_max, 0))
t <- t_max-t_min
min_RV <- min(plot_data$Mean)

# Sets break intervals based on the number of years spanned by data
if(t>=30){
  brk <- -10
}else if(t<30 & t>=10){
  brk <- -5
}else if(t<10 & t>=4){
  brk <- -2
}else if(t<4){
  brk <- -1
}

# Create plot object with data and trendline
p1 <- ggplot(data=plot_data,
      aes(x=YearMonthDec, y=Mean)) +
  # geom_line(size=0.75, color="#333333", alpha=0.6) +
  geom_point(shape=21, size=3, color="#333333", fill="#cccccc",
       alpha=0.75) +
  geom_line(data=KT.plot_data, aes(x=x, y=y),
      color="#000099", size=1.2, alpha=0.7) +
  labs(title=parameter,
    subtitle=paste0(params$managedarea),
    x="Year", y=y_labels) +
  scale_x_continuous(limits=c(t_min-0.25, t_max+0.25),
            breaks=seq(t_max_brk, t_min, brk)) +
  plot_theme 
# Creates ResultTable to display statistics below plot
ResultTable <- skt_stats[skt_stats$ManagedAreaName==params$managedarea, ] %>%
  select(RelativeDepth, N_Data, N_Years, Median, Independent, tau, p,
      SennSlope, SennIntercept, ChiSquared, pChiSquared, Trend)
# Create table object
t1 <- ggtexttable(ResultTable, rows=NULL,
        theme=ttheme(base_size=10)) %>%
  tab_add_footnote(text="p < 0.00005 appear as 0 due to rounding.\n
          SennIntercept is intercept value at beginning of
          record for monitoring location",
          size=10, face="italic")
# Arrange and display plot and statistic table
print(ggarrange(p1, t1, ncol=1, heights=c(0.85, 0.15)))
# Add extra space at the end to prevent the next figure from being too
# close.
cat("\n \n \n") 
rm(plot_data)
rm(KTset, leg)
rm(plot_data)
rm(KTset, leg)
```

\newpage

# Appendix II: Managed Area Summary Box Plots
Data is taken and grouped by `ManagedAreaName`. The scripts that create plots follow this format

1. Use the data set that only has `SufficientData` of `TRUE` for the desired managed area
2. Determine the earliest and latest year of the data to create x-axis scale and intervals
3. Determine the minimum, mean, and standard deviation for the data to be used for y-axis scales
   + Excludes the top 2% of values to reduce the impact of extreme outliers on the y-axis scale

4. Set what values are to be used for the x-axis, y-axis, and the variable that should determine groups for the box plots
5. Set the plot type as a box plot with the size of the outlier points
6. Create the title, x-axis, y-axis, and color fill labels
7. Set the y and x limits
8. Make the axis labels bold
9. Plot the arrangement as a set of panels

The following plots are arranged by `ManagedAreaName` with data grouped by `Year`, then `Year` and `Month`, then finally `Month` only. Each managed area will have 3 sets of plots, each with 3 panels in them. Each panel goes as follows:

1. Y-axis autoscaled
2. Y-axis set to be mean + 4 times the standard deviation
3. Y-axis set to be mean + 4 times the standard deviation for most recent 10 years of data


```{r BoxPlots_ManagedArea, warning=FALSE, fig.height=12, fig.width=10, eval=APP_Plots}
# Determine upper and lower bounds of time for x-axis
plot_data <- data[data$SufficientData==TRUE &
           data$ManagedAreaName==params$managedarea,]
year_lower <- min(plot_data$Year)
year_upper <- max(plot_data$Year)
# Determine upper and lower bounds of ResultValue for y-axis
min_RV <- min(plot_data$ResultValue)
mn_RV <- mean(plot_data$ResultValue[plot_data$ResultValue <
                    quantile(data$ResultValue, 0.98)])
sd_RV <- sd(plot_data$ResultValue[plot_data$ResultValue <
                  quantile(data$ResultValue, 0.98)])
# Sets x- and y-axis scale
x_scale <- ifelse(year_upper - year_lower > 30, 10, 5)
y_scale <- mn_RV + 4 * sd_RV

##Year plots
# Create plot object for auto-scaled y-axis plot
p1 <- ggplot(data=plot_data,
      aes(x=Year, y=ResultValue, group=Year)) +
  geom_boxplot(color="#333333", fill="#cccccc", outlier.shape=21,
         outlier.size=3, outlier.color="#333333",
         outlier.fill="#cccccc", outlier.alpha=0.75) +
  labs(subtitle="Autoscale",
    x="Year", y=y_labels) +
  scale_x_continuous(limits=c(year_lower - 1, year_upper + 1),
            breaks=rev(seq(year_upper,
                  year_lower, -x_scale))) +
  plot_theme
# Create plot object for y-axis scaled plot
p2 <- ggplot(data=plot_data,
      aes(x=Year, y=ResultValue, group=Year)) +
  geom_boxplot(color="#333333", fill="#cccccc", outlier.shape=21,
         outlier.size=3, outlier.color="#333333",
         outlier.fill="#cccccc", outlier.alpha=0.75) +
  labs(subtitle="Scaled to 4x Standard Deviation",
    x="Year", y=y_labels) +
  ylim(min_RV, y_scale) +
  scale_x_continuous(limits=c(year_lower - 1, year_upper + 1),
            breaks=rev(seq(year_upper,
                  year_lower, -x_scale))) +
  plot_theme
# Create plot object for y-axis scaled plot for past 10 years
p3 <- ggplot(data=plot_data[plot_data$Year >= year_upper - 10, ],
      aes(x=Year, y=ResultValue, group=Year)) +
  geom_boxplot(color="#333333", fill="#cccccc", outlier.shape=21,
         outlier.size=3, outlier.color="#333333",
         outlier.fill="#cccccc", outlier.alpha=0.75) +
  labs(subtitle="Scaled to 4x Standard Deviation, Last 10 Years",
    x="Year", y=y_labels) +
  ylim(min_RV, y_scale) +
  scale_x_continuous(limits=c(year_upper - 10.5, year_upper + 1),
            breaks=rev(seq(year_upper, year_upper - 10,-2))) +
  plot_theme
# Arrange plot objects
Yset <- ggarrange(p1, p2, p3, ncol=1)
# Create plot title object
p0 <- ggplot() + labs(title=paste0(parameter, " By Year"),
            subtitle=paste0(params$managedarea)) +
  plot_theme + theme(panel.border=element_blank(),
            panel.grid.major=element_blank(),
            panel.grid.minor=element_blank(),
            axis.line=element_blank())


## Year & Month Plots
# Create plot object for auto-scaled y-axis plot
p4 <- ggplot(data=plot_data,
      aes(x=YearMonthDec, y=ResultValue,
          group=YearMonth, color=as.factor(Month))) +
  geom_boxplot(fill="#cccccc", outlier.size=1.5, outlier.alpha=0.75) +
  labs(subtitle="Autoscale",
    x="Year", y=y_labels, color="Month") +
  scale_x_continuous(limits=c(year_lower - 1, year_upper + 1),
            breaks=rev(seq(year_upper,
                  year_lower, -x_scale))) +
  plot_theme +
  theme(legend.position="none")
# Create plot object for y-axis scaled plot
p5 <- ggplot(data=plot_data,
      aes(x=YearMonthDec, y=ResultValue,
          group=YearMonth, color=as.factor(Month))) +
  geom_boxplot(fill="#cccccc", outlier.size=1.5, outlier.alpha=0.75) +
  labs(subtitle="Scaled to 4x Standard Deviation",
    x="Year", y=y_labels, color="Month") +
  ylim(min_RV, y_scale) +
  scale_x_continuous(limits=c(year_lower - 1, year_upper + 1),
            breaks=rev(seq(year_upper,
                  year_lower, -x_scale))) +
  plot_theme +
  theme(legend.position="top", legend.box="horizontal") +
  guides(color=guide_legend(nrow=1))
# Create plot object for y-axis scaled plot for past 10 years
p6 <- ggplot(data=plot_data[plot_data$Year >= year_upper - 10, ],
      aes(x=YearMonthDec, y=ResultValue,
          group=YearMonth, color=as.factor(Month))) +
  geom_boxplot(fill="#cccccc", outlier.size=1.5, outlier.alpha=0.75) +
  labs(subtitle="Scaled to 4x Standard Deviation, Last 10 Years",
    x="Year", y=y_labels, color="Month") +
  ylim(min_RV, y_scale) +
  scale_x_continuous(limits=c(year_upper - 10.5, year_upper + 1),
            breaks=rev(seq(year_upper, year_upper - 10,-2))) +
  plot_theme +
  theme(legend.position="none")
# Create legend object
leg1 <- get_legend(p5)
# Arrange plots and legend
YMset <- ggarrange(leg1, p4, p5 + theme(legend.position="none"), p6,
         ncol=1, heights=c(0.1, 1, 1, 1))
# Create plot title object
p00 <- ggplot() + labs(title=paste0(parameter, " By Year & Month"),
             subtitle=paste0(params$managedarea)) + plot_theme +
  theme(panel.border=element_blank(),
     panel.grid.major=element_blank(),
     panel.grid.minor=element_blank(), axis.line=element_blank())

## Month Plots
# Create plot object for auto-scaled y-axis plot
p7 <- ggplot(data=plot_data,
      aes(x=Month, y=ResultValue,
          group=Month, fill=as.factor(Month))) +
  geom_boxplot(color="#333333", outlier.shape=21, outlier.size=3,
         outlier.color="#333333", outlier.alpha=0.75) +
  labs(subtitle="Autoscale",
    x="Month", y=y_labels, fill="Month") +
  scale_x_continuous(limits=c(0, 13), breaks=seq(3, 12, 3)) +
  plot_theme +
  theme(legend.position="none")
# Create plot object for y-axis scaled plot
p8 <- ggplot(data=plot_data,
      aes(x=Month, y=ResultValue,
          group=Month, fill=as.factor(Month))) +
  geom_boxplot(color="#333333", outlier.shape=21, outlier.size=3,
         outlier.color="#333333", outlier.alpha=0.75) +
  labs(subtitle="Scaled to 4x Standard Deviation",
    x="Month", y=y_labels, fill="Month") +
  ylim(min_RV, y_scale) +
  scale_x_continuous(limits=c(0, 13), breaks=seq(3, 12, 3)) +
  plot_theme +
  theme(legend.position="top", legend.box="horizontal") +
  guides(fill=guide_legend(nrow=1))
# Create plot object for y-axis scaled plot for past 10 years
p9 <- ggplot(data=plot_data[plot_data$Year >= year_upper - 10, ],
      aes(x=Month, y=ResultValue,
          group=Month, fill=as.factor(Month))) +
  geom_boxplot(color="#333333", outlier.shape=21, outlier.size=3,
         outlier.color="#333333", outlier.alpha=0.75) +
  labs(subtitle="Scaled to 4x Standard Deviation, Last 10 Years",
    x="Month", y=y_labels, fill="Month") +
  ylim(min_RV, y_scale) +
  scale_x_continuous(limits=c(0, 13), breaks=seq(3, 12, 3)) +
  plot_theme +
  theme(legend.position="none")
# Create legend object
leg2 <- get_legend(p8)
# Arrange plots and legend
Mset <- ggarrange(leg2, p7, p8 + theme(legend.position="none"), p9,
        ncol=1, heights=c(0.1, 1, 1, 1))
# Create title object
p000 <- ggplot() + labs(title=paste0(parameter, " By Month"),
           subtitle=paste0(params$managedarea)) + plot_theme +
  theme(panel.border=element_blank(),
     panel.grid.major=element_blank(),
     panel.grid.minor=element_blank(), axis.line=element_blank())
# Arrange and display plots with titles for all combinations
print(ggarrange(p0, Yset, ncol=1, heights=c(0.07, 1)))
print(ggarrange(p00, YMset, ncol=1, heights=c(0.07, 1)))
print(ggarrange(p000, Mset, ncol=1, heights=c(0.07, 1, 0.7)))

rm(plot_data)
rm(p1, p2, p3, p4, p5, p6, p7, p8, p9, p0, p00, p000, leg1, leg2,
  Yset, YMset, Mset)
```


