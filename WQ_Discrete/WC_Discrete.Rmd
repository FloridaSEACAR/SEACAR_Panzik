---
date: "Last compiled on `r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
    toc_depth: 2
    dev: png
    keep_md: yes
  word_document:
    toc: TRUE
    toc_depth: 2
  pdf_document:
    toc: TRUE
    toc_depth: 2
    dev: png
    extra_dependencies: ["float"]
    keep_md: yes
urlcolor: blue
geometry: "left=3cm,right=3cm"
params:
  managedarea: ma,
  p_inc: included_params,
  a_inc: included_acts,
  d_inc: included_depths
title: '`r paste(ma)`'
subtitle: '`r paste("SEACAR Water Quality Analysis")`'
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(
   warning=FALSE,
   message=FALSE,
   echo=FALSE,
   dpi=200
)
```


```{r libraries, message=FALSE, echo=FALSE, warning=FALSE, include=FALSE}
library(knitr)
library(data.table)
library(dplyr)
library(lubridate)
library(ggplot2)
library(ggpubr)
library(scales)
library(EnvStats)
library(tidyr)
library(kableExtra)
library(glue)
library(grid)
library(stringr)
options(scipen=999)
```

\newpage
# Seasonal Kendall Tau Analysis

Gets seasonal Kendall Tau statistics using the `kendallSeasonalTrendTest` from the `EnvStats` package. The `Trend` parameter is determined from a user-defined function based on the median, Senn slope, and p values from the data. Analysis modified from code created by Jason Scolaro for the [USF Water Atlas](https://sarasota.wateratlas.usf.edu/water-quality-trends/#analysis-overview)  

A significant result for the seasonal Kendall test indicates a monotonic increasing or decreasing trend across all seasons. The trend slope estimate is called 
the Sen slope, or the Theil-Sen estimator, and is calculated as the median of the slopes between all pairs of points within each season. The Sen intercept was
calculated as the median of *y â€“ mx* for all year-indicator value pairs in the time series, where *y* is the indicator value, *m* is the Sen slope, and *x* is 
the year corresponding with indicator value *y*.

```{r, results='asis'}
# Paste in descriptive snippet to provide VQ & threshold filtering info
cat(knitr::knit_child('snippet.Rmd', quiet=TRUE))
```




``` {r load_data_table function}
# For loading discrete data
# Load Data Table Function
load_data_table <- function(p, a="All", d="All", table) {
  
  # Declaring RDS file list of respective tables
  files <- list.files(here::here("output/tables/disc"),pattern = "\\.rds$")
  
  if (table == "data") {
    filename_string <- paste0(p,"_",table)
  } else {
    filename_string <- paste0(p,"_",a,"_",d,"_",table)
  }
  
  # subset file list to select desired table RDS file
  table_file <- paste0("output/tables/disc/",str_subset(files, filename_string))
  
  # importing RDS files
  df <- lapply(table_file, readRDS)

  return(df)
}


```



``` {r load_cont_data_table function}
# For loading continuous data
# Load Data Table Function
load_cont_data_table <- function(param, region, table) {
  
  # Declaring RDS file list of respective tables
  files <- list.files(here::here("output/tables/cont"),pattern = "\\.rds$")
  file_path <- paste0("_",param,"_", region,"_", table) 
  
  # subset file list to select desired table RDS file
  table_file <- paste0("output/tables/cont/",str_subset(files, file_path))
  
  # importing RDS files
  df <- readRDS(table_file)
  
  return(df)
}

```



```{r SKT_Trendlines_ManagedArea Function}

plot_trendlines <- function(p, a, d, activity_label, depth_label, y_labels, parameter) {

  MA_YM_Stats <- as.data.frame(load_data_table(p, a, d, "MA_MMYY_Stats"))
  skt_stats <- as.data.frame(load_data_table(p, a, d, "skt_stats"))

  ### SKT STATS ###
  # Gets x and y values for starting point for trendline
  KT.Plot <- skt_stats %>%
    group_by(ManagedAreaName) %>%
    summarize(x=decimal_date(EarliestSampleDate),
              y=(x-EarliestYear)*SennSlope+SennIntercept)
  # Gets x and y values for ending point for trendline
  KT.Plot2 <- skt_stats %>%
    group_by(ManagedAreaName) %>%
    summarize(x=decimal_date(LastSampleDate),
              y=(x-EarliestYear)*SennSlope+SennIntercept)
  # Combines the starting and endpoints for plotting the trendline
  KT.Plot <- bind_rows(KT.Plot, KT.Plot2)
  rm(KT.Plot2)
  KT.Plot <- as.data.table(KT.Plot[order(KT.Plot$ManagedAreaName), ])
  KT.Plot <- KT.Plot[!is.na(KT.Plot$y),]

  # Checking for missing values
  check_ym <- MA_YM_Stats %>%
    filter(ManagedAreaName == ma)
  
  if (nrow(check_ym) == 0) {
    invisible()
    # print("error")
  } else {
    # Gets data to be used in plot for managed area
    plot_data <- MA_YM_Stats[MA_YM_Stats$ManagedAreaName==ma,]

    # Gets trendline data for managed area
    KT.plot_data <- KT.Plot[KT.Plot$ManagedAreaName==ma,]

    #Determine max and min time (Year) for plot x-axis
    t_min <- min(plot_data$Year)
    t_max <- max(plot_data$YearMonthDec)
    t_max_brk <- as.integer(round(t_max, 0))
    t <- t_max-t_min
    min_RV <- min(plot_data$Mean)

    # Sets break intervals based on the number of years spanned by data
    if(t>=30){
      brk <- -10
    }else if(t<30 & t>=10){
      brk <- -5
    }else if(t<10 & t>=4){
      brk <- -2
    }else if(t<4){
      brk <- -1
    }

    # Create plot object with data and trendline
    p1 <- ggplot(data=plot_data,
          aes(x=YearMonthDec, y=Mean)) +
      # geom_line(size=0.75, color="#333333", alpha=0.6) +
      geom_point(shape=21, size=3, color="#333333", fill="#cccccc",
           alpha=0.75) +
      geom_line(data=KT.plot_data, aes(x=x, y=y),
          color="#000099", size=1.2, alpha=0.7) +
      labs(title=paste0(parameter,", ",activity_label, ", ",depth_label),
        subtitle=ma,
        x="Year", y=y_labels) +
      scale_x_continuous(limits=c(t_min-0.25, t_max+0.25),
                breaks=seq(t_max_brk, t_min, brk)) +
      plot_theme
    # Creates ResultTable to display statistics below plot
    ResultTable <- skt_stats[skt_stats$ManagedAreaName==ma, ] %>%
      select(RelativeDepth, N_Data, N_Years, Median, Independent, tau, p,
          SennSlope, SennIntercept, ChiSquared, pChiSquared, Trend)
    # Create table object
    t1 <- ggtexttable(ResultTable, rows=NULL,
            theme=ttheme(base_size=10)) %>%
      tab_add_footnote(text="p < 0.00005 appear as 0 due to rounding.\n
              SennIntercept is intercept value at beginning of
              record for monitoring location",
              size=10, face="italic")
    # Arrange and display plot and statistic table
    print(ggarrange(p1, t1, ncol=1, heights=c(0.85, 0.15)))
    # Add extra space at the end to prevent the next figure from being too
    # close.
    cat("\n \n \n")
    rm(plot_data)
    rm(MA_YM_Stats)
    # rm(KT.Plot)
    rm(skt_stats)
  }
}

```



```{r plot_boxplots modified function}

plot_boxplots <- function(p, a, d, activity_label, depth_label, y_labels, parameter, data) {
  # data <- as.data.frame(load_data_table(p, a, d, "data"))
  
  plot_title <- paste0(parameter,", ",activity_label, ", ",depth_label)
  
  # Determine upper and lower bounds of time for x-axis
  plot_data <- data[data$Include==TRUE &
                      data$ManagedAreaName==ma,]
  # plot_data <- data[data$ManagedAreaName==ma,]
  year_lower <- min(plot_data$Year)
  year_upper <- max(plot_data$Year)
  
  # Determine upper and lower bounds of ResultValue for y-axis
  min_RV <- min(plot_data$ResultValue)
  mn_RV <- mean(plot_data$ResultValue[plot_data$ResultValue <
                                        quantile(data$ResultValue, 0.98)])
  sd_RV <- sd(plot_data$ResultValue[plot_data$ResultValue <
                                      quantile(data$ResultValue, 0.98)])
  # Sets x- and y-axis scale
  x_scale <- ifelse(year_upper - year_lower > 30, 10, 5)
  y_scale <- mn_RV + 4 * sd_RV
  
  ##Year plots
  # Create plot object for auto-scaled y-axis plot
  p1 <- ggplot(data=plot_data,
               aes(x=Year, y=ResultValue, group=Year)) +
    geom_boxplot(color="#333333", fill="#cccccc", outlier.shape=21,
                 outlier.size=3, outlier.color="#333333",
                 outlier.fill="#cccccc", outlier.alpha=0.75) +
    labs(subtitle="By Year",
         x="Year", y=y_labels) +
    scale_x_continuous(limits=c(year_lower - 1, year_upper + 1),
                       breaks=rev(seq(year_upper,
                                      year_lower, -x_scale))) +
    plot_theme
  
  p4 <- ggplot(data=plot_data,
               aes(x=YearMonthDec, y=ResultValue,
                   group=YearMonth, color=as.factor(Month))) +
    geom_boxplot(fill="#cccccc", outlier.size=1.5, outlier.alpha=0.75) +
    labs(subtitle="By Year and Month",
         x="Year", y=y_labels, color="Month") +
    scale_x_continuous(limits=c(year_lower - 1, year_upper + 1),
                       breaks=rev(seq(year_upper,
                                      year_lower, -x_scale))) +
    plot_theme +
    theme(legend.position="none")
  
  # Month Plots
  # Create plot object for auto-scaled y-axis plot
  p7 <- ggplot(data=plot_data,
               aes(x=Month, y=ResultValue,
                   group=Month, fill=as.factor(Month))) +
    geom_boxplot(color="#333333", outlier.shape=21, outlier.size=3,
                 outlier.color="#333333", outlier.alpha=0.75) +
    labs(subtitle="By Month",
         x="Month", y=y_labels, fill="Month") +
    scale_x_continuous(limits=c(0, 13), breaks=seq(3, 12, 3)) +
    plot_theme +
    theme(legend.position="none",
          axis.text.x=element_text(angle = 0, hjust = 1))
  
  set <- ggarrange(p1 + rremove("ylab"), p4 + rremove("ylab"), p7 + rremove("ylab"), ncol=1)
  
  p0 <- ggplot() + labs(title=plot_title, 
                        subtitle=ma) + 
    plot_theme +
    theme(panel.border=element_blank(), panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(), axis.line=element_blank())
  
  annotate_figure(p0, left = textGrob(y_labels, rot = 90, vjust = 1, gp = gpar(cex = 1.3)))
  
  # Arrange title on plots
  Yset <- ggarrange(p0, set, ncol=1, heights=c(0.07, 1))
  Yset_annotated <- annotate_figure(Yset,
                left = text_grob(y_labels, rot = 90, family = "Arial", size = 10))
  
  print(Yset_annotated)
  
  rm(plot_data)
  rm(p1, p4, p7, p0, Yset, Yset_annotated)
}

```



```{r plot_all continuous function}

plot_cont <- function(p, y_labels, parameter, cont_data) {
  data <- cont_data %>% filter(ManagedAreaName == ma)
  
  Mon_YM_Stats <- as.data.frame(load_cont_data_table(p, region, "Mon_YM_Stats"))
  skt_stats <- as.data.frame(load_cont_data_table(p, region, "skt_stats"))
  
  skt_stats <- skt_stats %>% 
    filter(ManagedAreaName==ma)
  
  # Checking for missing values
  Mon_YM_Stats <- Mon_YM_Stats %>%
    filter(ManagedAreaName == ma & ParameterName == parameter)
  
  ### SKT STATS ###
  # Gets x and y values for starting point for trendline
  KT.Plot <- skt_stats %>%
    group_by(MonitoringID) %>%
    summarize(x=decimal_date(EarliestSampleDate),
              y=(x-EarliestYear)*SennSlope+SennIntercept)
  # Gets x and y values for ending point for trendline
  KT.Plot2 <- skt_stats %>%
    group_by(MonitoringID) %>%
    summarize(x=decimal_date(LastSampleDate),
              y=(x-EarliestYear)*SennSlope+SennIntercept)
  # Combines the starting and endpoints for plotting the trendline
  KT.Plot <- bind_rows(KT.Plot, KT.Plot2)
  rm(KT.Plot2)
  KT.Plot <- as.data.table(KT.Plot[order(KT.Plot$MonitoringID), ])
  KT.Plot <- KT.Plot[!is.na(KT.Plot$y),]
  
  # unique monitoring location IDs for each managed area
  MonIDs <- unique(data$MonitoringID)
  n <- length(MonIDs)
  
  if (length(MonIDs) == 0){
    print("There are no monitoring locations that qualify.")
  } else {
    # Begins looping through each monitoring location
    for (id in MonIDs) {
      
      ##################
      ### TRENDPLOTS ###
      ##################
      
      # Gets data to be used in plot for monitoring location
      plot_data <- Mon_YM_Stats[Mon_YM_Stats$MonitoringID==id,]
      
      if (nrow(plot_data) > 0) {
        # Gets trendline data for monitoring location
        KT.plot_data <- KT.Plot[KT.Plot$MonitoringID==id,]
        #Determine max and min time (Year) for plot x-axis
        t_min <- min(plot_data$Year)
        t_max <- max(plot_data$YearMonthDec)
        t_max_brk <- as.integer(round(t_max, 0))
        t <- t_max-t_min
        min_RV <- min(plot_data$Mean)
        # Creates break intervals for plots based on number of years of data
        if(t>=30){
          # Set breaks to every 10 years if more than 30 years of data
          brk <- -10
        }else if(t<30 & t>=10){
          # Set breaks to every 5 years if between 30 and 10 years of data
          brk <- -5
        }else if(t<10 & t>=4){
          # Set breaks to every 2 years if between 10 and 4 years of data
          brk <- -2
        }else if(t<4 & t>=2){
          # Set breaks to every year if between 4 and 2 years of data
          brk <- -1
        }else if(t<2){
          # Set breaks to every year if less than 2 years of data
          brk <- -1
          # Sets t_max to be 1 year greater and t_min to be 1 year lower
          # Forces graph to have at least 3 tick marks
          t_max <- t_max+1
          t_min <- t_min-1
        }
        # Get name of managed area
        MA_name <- skt_stats$ManagedAreaName[skt_stats$MonitoringID==id]
        # Get program location name
        Mon_name <- paste0(skt_stats$ProgramID[skt_stats$MonitoringID==id],
                           "\n", skt_stats$ProgramName[skt_stats$MonitoringID==id], "\n",
                           skt_stats$ProgramLocationID[skt_stats$MonitoringID==id])
        mon_name_short <- skt_stats$ProgramLocationID[skt_stats$MonitoringID==id]
        # Create plot object with data and trendline
        p1 <- ggplot(data=plot_data,
                     aes(x=YearMonthDec, y=Mean)) +
          geom_point(shape=21, size=3, color="#333333", fill="#cccccc",
                     alpha=0.75) +
          geom_line(data=KT.plot_data, aes(x=x, y=y),
                    color="#000099", size=1.2, alpha=0.7) +
          labs(title=paste0(MA_name, "\n", Mon_name),
               subtitle=parameter,
               x="Year", y=y_labels) +
          scale_x_continuous(limits=c(t_min-0.25, t_max+0.25),
                             breaks=seq(t_max_brk, t_min, brk)) +
          plot_theme
        
        # Creates ResultTable to display statistics below plot
        ResultTable <- skt_stats[skt_stats$MonitoringID==id, ] %>%
          select(RelativeDepth, N_Data, N_Years, Median, Independent, tau, p,
                 SennSlope, SennIntercept, ChiSquared, pChiSquared, Trend)
        # Create table object
        t1 <- ggtexttable(ResultTable, rows=NULL,
                          theme=ttheme(base_size=10)) %>%
          tab_add_footnote(text="p < 0.00005 appear as 0 due to rounding.\n
                              SennIntercept is intercept value at beginning of
                              record for monitoring location",
                           size=10, face="italic")
        
        ### Monitoring Station Name Label ###
        mon_title <- glue("### {mon_name_short}")
        cat(mon_title, "\n\n")
        
        # Arrange and display plot and statistic table
        print(ggarrange(p1, t1, ncol=1, heights=c(0.85, 0.15)))
        # Add extra space at the end to prevent the next figure from being too close
        cat("\n \n \n")
      }
      
      ################
      ### BOXPLOTS ###
      ################
      
      plot_data <- data %>% 
        filter(Include == TRUE, MonitoringID == id)
      
      if (nrow(plot_data) > 0) {
        
        # Determine upper and lower bounds of time for x-axis
        year_lower <- min(plot_data$Year)
        year_upper <- max(plot_data$Year)
        
        # Determine upper and lower bounds of ResultValue for y-axis
        min_RV <- min(plot_data$ResultValue)
        mn_RV <- mean(plot_data$ResultValue[plot_data$ResultValue <
                                              quantile(data$ResultValue, 0.98)])
        sd_RV <- sd(plot_data$ResultValue[plot_data$ResultValue <
                                            quantile(data$ResultValue, 0.98)])
        
        # Sets x- and y-axis scale
        x_scale <- ifelse(year_upper - year_lower > 30, 10, 5)
        y_scale <- mn_RV + 4 * sd_RV
        
        # Gets managed area name for title
        MA_name <- unique(data$ManagedAreaName[data$MonitoringID==id])
        
        # Gets program location name for title
        Mon_name <- unique(paste0(data$ProgramID[data$MonitoringID==id],
                                  "\n", data$ProgramName[data$MonitoringID==id], "\n",
                                  data$ProgramLocationID[data$MonitoringID==id]))
        
        ##Year plots
        # Create plot object for auto-scaled y-axis plot
        p1 <- ggplot(data=plot_data,
                     aes(x=Year, y=ResultValue, group=Year)) +
          geom_boxplot(color="#333333", fill="#cccccc", outlier.shape=21,
                       outlier.size=3, outlier.color="#333333",
                       outlier.fill="#cccccc", outlier.alpha=0.75) +
          labs(subtitle="By Year",
               x="Year", y=y_labels) +
          scale_x_continuous(limits=c(year_lower - 1, year_upper + 1),
                             breaks=rev(seq(year_upper,
                                            year_lower, -x_scale))) +
          plot_theme
        
        ## Year & Month Plots
        p4 <- ggplot(data=plot_data,
                     aes(x=YearMonthDec, y=ResultValue,
                         group=YearMonth, color=as.factor(Month))) +
          geom_boxplot(fill="#cccccc", outlier.size=1.5, outlier.alpha=0.75) +
          labs(subtitle="By Year and Month",
               x="Year", y=y_labels, color="Month") +
          scale_x_continuous(limits=c(year_lower - 1, year_upper + 1),
                             breaks=rev(seq(year_upper,
                                            year_lower, -x_scale))) +
          plot_theme +
          theme(legend.position="none")
        
        ## Month Plots
        # Create plot object for auto-scaled y-axis plot
        p7 <- ggplot(data=plot_data,
                     aes(x=Month, y=ResultValue,
                         group=Month, fill=as.factor(Month))) +
          geom_boxplot(color="#333333", outlier.shape=21, outlier.size=3,
                       outlier.color="#333333", outlier.alpha=0.75) +
          labs(subtitle="By Month",
               x="Month", y=y_labels, fill="Month") +
          scale_x_continuous(limits=c(0, 13), breaks=seq(3, 12, 3)) +
          plot_theme +
          theme(legend.position="none",
                axis.text.x=element_text(angle = 0, hjust = 1))
        
        set <- ggarrange(p1 + rremove("ylab"), p4 + rremove("ylab"), p7 + rremove("ylab"), ncol=1)
        
        # Create title object
        p0 <- ggplot() + labs(title=Mon_name) + 
          plot_theme +
          theme(panel.border=element_blank(),
                panel.grid.major=element_blank(),
                panel.grid.minor=element_blank(), 
                axis.line=element_blank())
        
        annotate_figure(p0, left = textGrob(y_labels, rot = 90, vjust = 1, gp = gpar(cex = 1.3)))
        
        # Arrange title on plots
        Yset <- ggarrange(p0, set, ncol=1, heights=c(0.07, 1))
        Yset_annotated <- annotate_figure(Yset,
                                          left = text_grob(y_labels, rot = 90, family = "Arial", size = 10))
        
        print(Yset_annotated)
        
        cat("\n \n \n")
        
        rm(plot_data)
        rm(p1, p4, p7, p0, Yset, Yset_annotated)
      }

    }
  }
}

```



```{r VQ_Summary Barplot function, results='asis'}

plot_vq_barplot <- function(p, a, d, activity_label, depth_label, y_labels, parameter, data) {
  
  VQ_Summary <- as.data.frame(load_data_table(p, a, d, "VQSummary"))
  
  # Filter and subset dataframe for managed area
  ma_vq_summary <- VQ_Summary %>% filter(ManagedAreaName == ma)
  
  # VQSummary conditions for qualifying VQ values
  vq_condition <- ma_vq_summary$N_H !=0 | ma_vq_summary$N_I != 0 | ma_vq_summary$N_Q != 0 | ma_vq_summary$N_S != 0 | ma_vq_summary$N_U != 0
  
  # apply VQ_conditions to subset dataframe
  filtered_vq <- ma_vq_summary[vq_condition, ]
  
  # check to see if there are any qualifying VQ values, if not, skip
  if (nrow(filtered_vq) != 0) {
    
    # select respective perc_vq columns
    plot_data <- filtered_vq %>% 
      select(Year, N_Total, N_H, perc_H, N_I, perc_I, N_Q, perc_Q, N_S, perc_S, N_U, perc_U) %>%
      mutate_if(is.numeric, round, 2)
    
    # show only relevant columns for table display
    plot_data <- plot_data %>% 
      select(-where(~ all(. == 0)))

    # convert data format to "long" for plotting
    plot_data_long <- tidyr::pivot_longer(plot_data, 
                                          cols = starts_with("perc_"), 
                                          names_to = "Category", 
                                          values_to = "Percentage")
    
    # remove values when their VQ not included
    plot_data_long <- plot_data_long %>% 
      filter(Percentage != 0)
    
    # set year bounds for upper and lower
    year_lower <- min(plot_data_long$Year)
    year_upper <- max(plot_data_long$Year)
    
    # Use similar x-scaling to previous charts # may change
    x_scale <- ifelse(year_upper - year_lower > 30, 10, 
                      ifelse(year_upper == year_lower, 1, 3))
    
    # set title label
    lab_title <- paste0("Percentage Distribution of Value Qualifiers by year for ", d," Depths -  ", parameter)
    
    # plot results
    vq_plot <- ggplot(plot_data_long, aes(x=Year, y=Percentage, fill=Category)) + 
      geom_bar(stat = "identity", position="stack") +
      #geom_text(aes(label = ifelse(Category == "perc_H", N_H,
      #                       ifelse(Category == "perc_I", N_I,
      #                              ifelse(Category == "perc_Q", N_Q,
      #                                     ifelse(Category == "perc_S", N_S, N_U))))),
      #    position = position_dodge(width = 0.9),
      #    vjust = -0.1) +  # Adjust label position
      labs(title = lab_title,
           subtitle = paste(ma),
           x = "Year",
           y = "Percentage") +
      ylim(0, 100) +
      scale_x_continuous(limits=c(year_lower - 1, year_upper + 1),
                         breaks=rev(seq(year_upper,
                                        year_lower, -x_scale))) +
      scale_fill_manual(values=c("#00ADAE","#65CCB3","#AEE4C1","#FDE8A8","#F8CD6D"),
                        breaks=c("perc_H","perc_I","perc_Q","perc_S","perc_U"),
                        labels=c("H", "I", "Q", "S", "U")) +
      plot_theme
    
    # print plots
    print(vq_plot)
    
    # Replace 0 values with NA, to be modified to empty string with kable function
    plot_data[plot_data == 0] <- NA
    options(knitr.kable.NA = "")
    
    # add text table beneath plot
    vq_table <- kable(plot_data, 
                      format="simple",
                      digits = 1,
                      caption=paste0("Value Qualifiers for ", parameter)) %>%
      kable_styling(latex_options="scale_down",
                    position = "center")
    
    cat("  \n")
    print(vq_table)
    
    # list of programs with VQ data
    vq <- data %>% 
      filter(Include==TRUE, ManagedAreaName==ma, ValueQualifier!="NA") %>%
      select(ProgramID, ProgramName)
    
    vq_program_id <- unique(vq$ProgramID)

    cat("\n **Programs containing Value Qualified data:** \n \n")

    # Display ProgramName below data table
    for (p_id in vq_program_id) {
      p_name <- unlist(unique(vq %>% filter(ProgramID == p_id) %>% select(ProgramName)))
      cat(paste0("*",p_id,"*", " - ",p_name, "  \n"))
    }
    
    cat("  \n")
    
    # add description for each VQ shown
    vq <- list("N_H","N_I","N_Q","N_S","N_U")
    vq_desc <- list("H - Value based on field kit determiniation; results may not be accurate. 
                This code shall be used if a field screening test (e.g., field gas chromatograph data, 
                immunoassay, or vendor-supplied field kit) was used to generate the value and the field 
                kit or method has not been recognized by the Department as equivalent to laboratory methods.",
                
                "I - The reported value is greater than or equal to the laboratory method detection 
                limit but less than the laboratory practical quantitation limit.",
                
                "Q - Sample held beyond the accepted holding time. This code shall be used if the value is derived 
                from a sample that was prepared or analyzed after the approved holding time restrictions for sample 
                preparation or analysis.",
                
                "S - Secchi disk visible to bottom of waterbody. The value reported is the depth of the waterbody 
                at the location of the Secchi disk measurement.",
                
                "U - Indicates that the compound was analyzed for but not detected. This symbol shall be used to indicate 
                that the specified component was not detected. The value associated with the
                qualifier shall be the laboratory method detection limit. Unless requested by the client, 
                less than the method detection limit values shall not be reported ")

    vq_list <- setNames(as.list(vq_desc), vq)
    
    cat("  \n")
    cat("**Value Qualifiers**  \n \n")
    cat("  \n")
    
    # loop to add description if the corresponding VQ is listed above
    for (vq in names(vq_list)) {
      if (vq %in% names(plot_data)) {
        cat(unlist(vq_list[vq]), sep = '\n')
        cat("\n")
      }
    }
    
    rm(VQ_Summary, filtered_vq, plot_data, plot_data_long, vq_plot)
  } else {
    cat(paste0("There are no qualifying Value Qualifiers for ", parameter, " in ", ma))
    cat("\n \n \n")
  }
}

```



```{r dynamic_variables}
# Create conditions to determine if plots/text are shown (Discrete)
dynamic_vars <- list()
for (param in p_inc) {
  val <- ifelse(param %in% p_inc, TRUE, FALSE)
  assign(paste0("show_", param), val, envir = .GlobalEnv)
  dynamic_vars[[param]] <- get(paste0("show_",param))
}
```


\newpage
# Discrete Parameters

Discrete indicators must have a minimum of ten years of data within the geographic range of the analysis in order to assess trends. For the 
preferred seasonal Kendall Tau analysis to be performed there must be data from at least two months in common across at least two 
consecutive years within the RCP managed area being analyzed.  

The discrete water quality analysis will include surface and bottom measurements; mid-column data will not be included due to 
lower confidence that depths were comparable. Upper and lower limits for discrete samples are based on thresholds established by the
Division of Environmental Assessment and Restoration for WIN.  

Include threshold table??



```{r discrete file list, results='asis'}

cat("The following files were used in the discrete analysis:  \n\n")
for (param in p_inc){
  file_name <- file_list_df[param][[1]]
  cat(paste0("* ", file_name, "  \n"))
}

```



```{r PlottingDiscrete, warning=FALSE, fig.height=9, fig.width=10, results="asis", eval=TRUE}

# Start looping for each parameter
for (param in p_inc) {
  
  # load overall discrete data
  data <- as.data.frame(load_data_table(param, table="data"))
  
  # getting full parameter & unit names
  parameter <- unique(data$ParameterName)
  unit <- unique(data$ParameterUnits)
  
  # defining labels for y-axis
  y_labels <- ifelse(param == "pH", parameter, paste0(parameter, " (" , unit, ")"))
  
  # Calling dynamic variables to create subtitles for each param
  if (get(paste0("show_", param))) {
    cat("\\newpage")
    subtitle <- glue("## {parameter}")
    cat(subtitle, "\n\n")
  }
  
  #Because secchi depth is does not have a bottom measurement, this statement skips
  #Secchi depth for bottom
  if (param == "Secchi"){
    depth <- "Surface"
  } else {
    depth <- "All"
  }
  
  # Choosing which analyses to plot, when to combine 
  if (param == "ChlaC" |
      param == "Chla" |
      param == "CDOM" |
      param == "TN" |
      param == "TP") {activity = "Lab"} else if (
        param == "DO" |
        param == "DOS" |
        param == "pH" |
        param == "Secchi" |
        param == "TempW") {activity = "Field"} else if (
          param == "Sal" |
          param == "TSS" |
          param == "Turb") {activity = "All"}
  
  if (activity == "All") {
    activity_label <- "Lab and Field Combined"
  } else if (activity == "Field" | activity == "Lab") {
    activity_label <- activity
  }
  
  if (depth == "All") {
    depth_label <- "All Depths"
  } else if (depth == "Surface") {
    depth_label <- "Surface"
  }
  
  # Exception to include TN calculation logic
  # Loads external .Rmd for ease of formatting
  if (param == "TN") {
    cat(knitr::knit_child('TN_Calculation_Description.Rmd', quiet=TRUE))
    cat("\\newpage")
  }
  
  ###############################
  ### Begin Plotting Discrete ###
  ###############################
  
  # SKT Header (### makes sub-heading)
  cat(glue("### Discrete Seasonal Kendall-Tau Trend Analysis"), "\n\n")

  # Produce discrete SKT-trendplots
  plot_trendlines(param, activity, depth, activity_label, depth_label, y_labels, parameter)
  
  # Produce boxplots
  plot_boxplots(param, activity, depth, activity_label, depth_label, y_labels, parameter, data)

  # Produce VQ-barplots
  plot_vq_barplot(param, activity, depth, activity_label, depth_label, y_labels, parameter, data)
  
  # Produce data-exclusion-tables
  # data_exclusion_table(data, parameter)
  
  # Produce VQ-scatter-plots
  # plot_vq_Scatterplot(param, activity, depth, activity_label, depth_label, y_labels, parameter, data)
}

```


\setcounter{tocdepth}{3}
\newpage
# Continuous Parameters

Continuous indicators must have a minimum of five years of data within the geographic range of the analysis in order to assess trends. For the 
preferred seasonal Kendall Tau analysis to be performed there must be data from at least two months in common across at least two 
consecutive years within the RCP managed area being analyzed.  

The following table shows the continuous stations included in this managed area.


```{r continuous file list, results='asis', eval=TRUE}
# extract region for each MA to determine which cont. file to load
region <- MA_All %>% filter(ManagedAreaName == ma) %>% pull(Region)

cat("The following files were used in the continuous analysis:  \n\n")
for (param in cont_params_short){
  par_reg <- paste0(param, "_", region)
  try(
    cat(paste0("* ", cont_file_list_df[par_reg][[1]], "  \n")),
    silent = TRUE
  )
}

```



```{r, station_count_table, results='asis', eval=TRUE}

station_count_table <- function(cont_data){

  # create frame to show available stations
  # show how many are included/excluded in the report
  stations <- cont_data %>% 
    filter(ManagedAreaName == ma) %>% 
    distinct(ProgramLocationID, ProgramName, Use_In_Analysis)
  
  # table
  stations_table <- kable(stations,
                          format="simple",
                          caption=paste0("Number of Continuous Stations in ", ma)) %>%
    kable_styling(latex_options="scale_down",
                  position = "center")
  
  print(stations_table)
  cat("  \n\n")
  
  # n stations total, n stations included (Use_In_Analysis)
  n_stations <- nrow(stations)
  n_stations_inc <- nrow(stations[stations$Use_In_Analysis==TRUE, ])
  
  # print text statement
  cat(paste0("There are ", n_stations, " stations in ", ma, ".  \n\n"))
  cat(paste0(n_stations_inc, " out of ", n_stations, " are included in this report."))
  cat("  \n\n")

}

```



```{r PlottingContinuous, warning=FALSE, fig.height=9, fig.width=10, results='asis', eval=TRUE}

# Cont. Data exports do not contain full parameter names or units
# Create dataframe containing that info
cont_params_long <- c("Dissolved Oxygen","Dissolved Oxygen Saturation","pH",
                      "Salinity","Turbidity","Water Temperature")
cont_param_units <- c("mg/L","%","pH","ppt","NTU","Degrees C")

cont_param_df <- data.frame(param_short = cont_params_short,
                            parameter = cont_params_long,
                            unit = cont_param_units)

# extract region for each MA to determine which cont. file to load
region <- MA_All %>% filter(ManagedAreaName == ma) %>% pull(Region)

# loop through cont. params
for (i in 1:length(cont_params_short)){
  param <- cont_params_short[i]
  
  # load cont data for a given region containing MA
  cont_data <- as.data.frame(load_cont_data_table(param, region, table="data"))
  
  # run first time only to display stations
  if (i==1) {
    station_count_table(cont_data)
  }
  
  # getting full parameter & unit names
  parameter <- cont_param_df %>% filter(param_short == param) %>% pull(parameter)
  unit <- cont_param_df %>% filter(param_short == param) %>% pull(unit)
  
  # defining labels for y-axis
  y_labels <- ifelse(param == "pH", parameter, paste0(parameter, " (" , unit, ")"))
  
  ###########################
  ### Begin Plotting Cont ###
  ###########################
  
  cat("\\newpage")
  subtitle <- glue("## {parameter}")
  cat(subtitle, "\n\n")
  
  plot_cont(param, y_labels, parameter, cont_data)
}


```

